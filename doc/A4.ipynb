{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EG3lKK9erRny"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from random import seed, shuffle\n",
        "import os,sys\n",
        "import traceback\n",
        "import numpy as np\n",
        "from random import seed, shuffle\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "from cvxpy import *\n",
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade pip\n",
        "!pip install setuptools==57.5.0 #adde\n",
        "!pip3 install dccp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rl-LmS423jra",
        "outputId": "31c90493-ad97-41a1-e2a1-f44d39bdddc9"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting setuptools==57.5.0\n",
            "  Using cached setuptools-57.5.0-py3-none-any.whl (819 kB)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 69.0.2\n",
            "    Uninstalling setuptools-69.0.2:\n",
            "      Successfully uninstalled setuptools-69.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 57.5.0 which is incompatible.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 57.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-57.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dccp in /usr/local/lib/python3.10/dist-packages (1.0.5)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from dccp) (1.3.2)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (3.2.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (1.11.3)\n",
            "Collecting setuptools>65.5.1 (from cvxpy>=1.0->dccp)\n",
            "  Using cached setuptools-69.0.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy>=1.0->dccp) (0.1.7.post0)\n",
            "Using cached setuptools-69.0.2-py3-none-any.whl (819 kB)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.5.0\n",
            "    Uninstalling setuptools-57.5.0:\n",
            "      Successfully uninstalled setuptools-57.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-69.0.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv('https://github.com/propublica/compas-analysis/raw/master/compas-scores-two-years.csv')\n"
      ],
      "metadata": {
        "id": "SGpIAtdELfVM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "df['day_stayed'] = (pd.to_datetime(df[\"c_jail_out\"]) - pd.to_datetime(df[\"c_jail_in\"])).astype('timedelta64[h]') / 24\n",
        "df = df[df.day_stayed > 0]\n",
        "\n",
        "# Select relevant variables\n",
        "df = df[['sex', 'age_cat', 'race', 'decile_score', 'score_text', 'priors_count', 'days_b_screening_arrest',\n",
        "         'v_decile_score', 'v_score_text', 'c_charge_degree', 'is_violent_recid', 'is_recid', 'day_stayed', 'two_year_recid']]\n",
        "\n",
        "# Filter for two races\n",
        "df = df[df.race.isin(['African-American', 'Caucasian'])]\n",
        "\n",
        "# Encoding categorical variables\n",
        "df['sex'].replace(['Male', 'Female'], [1, 0], inplace=True)\n",
        "df['race'].replace(['Caucasian', 'African-American'], [1, 0], inplace=True)\n",
        "df['score_text'].replace(['Low', 'Medium', 'High'], [0, 1, 2], inplace=True)\n",
        "df['v_score_text'].replace(['Low', 'Medium', 'High'], [0, 1, 2], inplace=True)\n",
        "df['age_cat'].replace(['Less than 25', '25 - 45', 'Greater than 45'], [0, 1, 2], inplace=True)\n",
        "df['c_charge_degree'].replace(['M', 'F'], [1, 0], inplace=True)\n"
      ],
      "metadata": {
        "id": "ywX_Mh6Nh498"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame with features and labels\n",
        "X = df.drop('two_year_recid', axis=1).values\n",
        "y = df['two_year_recid'].values\n",
        "y = np.where(y == 0, -1, 1)  # Convert labels to {-1, 1}\n",
        "sensitive_attr = df['race'].values\n",
        "\n",
        "# Adding an intercept term to X\n",
        "intercept = np.ones((X.shape[0], 1))  # Column of ones\n",
        "X = np.hstack((intercept, X))\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test, sensitive_attr_train, sensitive_attr_test = train_test_split(\n",
        "    X, y, sensitive_attr, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "FGxHl1-Ka3ka"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install dccp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Tl1xSNkkwr",
        "outputId": "2337f952-1638-45d8-fc88-e1b629a43b64"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dccp\n",
            "  Downloading dccp-1.0.5-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from dccp) (1.3.2)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (3.2.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (1.11.3)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.0->dccp) (67.7.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy>=1.0->dccp) (0.1.7.post0)\n",
            "Installing collected packages: dccp\n",
            "Successfully installed dccp-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Fairness Constraints:** The get_constraint_list_cov function builds the fairness constraints based on the sensitive attribute and the thresholds defined in sensitive_attrs_to_cov_thresh. These constraints aim to ensure that the difference in treatment of different groups (based on the sensitive attribute) does not exceed specified thresholds."
      ],
      "metadata": {
        "id": "4MKojysbAcRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fairness_covariance(theta, features, true_labels, sensitive_features):\n",
        "    assert(features.shape[0] == sensitive_features.shape[0])\n",
        "    if len(set(sensitive_features)) != 2:\n",
        "        raise Exception(\"Non-binary attribute detected. This function handles binary attributes only.\")\n",
        "\n",
        "    predicted_labels = np.sign(np.dot(features, theta))\n",
        "\n",
        "    group_totals = {ct: {} for ct in [0, 1, 2]}\n",
        "    group_averages = {ct: {} for ct in [0, 1, 2]}\n",
        "    covariance_sums = {ct: {} for ct in [0, 1, 2]}\n",
        "\n",
        "    for group_val in set(sensitive_features):\n",
        "        group_totals[0][group_val] = np.sum(sensitive_features == group_val)\n",
        "        group_totals[1][group_val] = np.sum(np.logical_and(sensitive_features == group_val, true_labels == -1))\n",
        "        group_totals[2][group_val] = np.sum(np.logical_and(sensitive_features == group_val, true_labels == 1))\n",
        "\n",
        "    for ct in [0, 1, 2]:\n",
        "        for group_val in set(sensitive_features):\n",
        "            total = group_totals[ct].get(group_val, 0) + group_totals[ct].get(1-group_val, 0)\n",
        "            if total > 0:\n",
        "                group_averages[ct][group_val] = group_totals[ct].get(group_val, 0) / float(total)\n",
        "            else:\n",
        "                group_averages[ct][group_val] = 0\n",
        "\n",
        "    label_product = np.array(predicted_labels * true_labels)\n",
        "    for group_val in set(sensitive_features):\n",
        "        idx = sensitive_features == group_val\n",
        "        dist_bound_prod = label_product[idx]\n",
        "        for ct in [0, 1, 2]:\n",
        "            if ct == 0:\n",
        "                covariance_sums[ct][group_val] = np.sum(np.minimum(0, dist_bound_prod)) * (group_averages[ct][group_val] / len(features))\n",
        "            elif ct == 1:\n",
        "                covariance_sums[ct][group_val] = np.sum(np.minimum(0, ((1 - true_labels[idx]) / 2) * dist_bound_prod)) * (group_averages[ct][group_val] / np.sum(true_labels == -1))\n",
        "            else:\n",
        "                covariance_sums[ct][group_val] = np.sum(np.minimum(0, ((1 + true_labels[idx]) / 2) * dist_bound_prod)) * (group_averages[ct][group_val] / np.sum(true_labels == 1))\n",
        "\n",
        "    return covariance_sums\n",
        "\n",
        "\n",
        "\n",
        "def predict(X, theta):\n",
        "    # Using numpy's dot product for matrix multiplication\n",
        "    return np.sign(np.dot(X, theta))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3DnimBxBcdZw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constraint parameters\n",
        "constraint_params = {\n",
        "    \"sensitive_attrs_to_cov_thresh\": {\n",
        "        1: 0.05,  # Threshold for FPR\n",
        "        2: 0.05   # Threshold for FNR\n",
        "    },\n",
        "    \"cons_type\": 4,  # Indicates both FPR and FNR constraints are applied\n",
        "    \"tau\": 0.005,    # DCCP method parameter\n",
        "    \"mu\": 1.2        # DCCP method parameter\n",
        "}\n",
        "# Train the model with fairness constraints\n",
        "trained_theta = train_model(X_train, y_train, sensitive_attr_train, eps=1e-5, constraint_params=constraint_params)\n",
        "\n",
        "# Evaluate the trained model using get_clf_stats\n",
        "train_accuracy, test_accuracy, train_fair_cov, test_fair_cov, train_fair_metrics, test_fair_metrics = get_clf_stats(\n",
        "    trained_theta, X_train, y_train, sensitive_attr_train, X_test, y_test, sensitive_attr_test\n",
        ")\n",
        "\n",
        "# Output the results\n",
        "print(f\"Training Accuracy: {train_accuracy}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(\"Training Fairness Metrics:\", train_fair_metrics)\n",
        "print(\"Test Fairness Metrics:\", test_fair_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G4NcY5bco9t",
        "outputId": "754f3319-6c0d-4658-bda6-95181b0bf42e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9692982456140351\n",
            "Training Accuracy: 0.9681947795569203\n",
            "Test Accuracy: 0.9692982456140351\n",
            "Training Fairness Metrics: {0: {'fp': 100, 'fn': 0, 'fpr': 0.07776049766718507, 'fnr': 0.0, 'acc': 0.9635435654393001}, 1: {'fp': 45, 'fn': 0, 'fpr': 0.041743970315398886, 'fnr': 0.0, 'acc': 0.9752202643171806}}\n",
            "Test Fairness Metrics: {0: {'fp': 26, 'fn': 0, 'fpr': 0.08333333333333333, 'fnr': 0.0, 'acc': 0.9614243323442137}, 1: {'fp': 9, 'fn': 0, 'fpr': 0.032490974729241874, 'fnr': 0.0, 'acc': 0.98068669527897}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use get_constraint_list_cov in logistic regression model training process, it adds constraints to the optimization problem to control the FPR and FNR for different groups based on the sensitive attribute"
      ],
      "metadata": {
        "id": "CoLhsaZCWW28"
      }
    }
  ]
}